---
title: "Life Policy Book Analysis: Detailed Lapse Analysis"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "2018-01-04"
output:
  html_document:
    toc: true
    number_sections: true
    fig_caption: yes
    theme: cerulean
  pdf_document: default
---


```{r knit_opts, include = FALSE}
rm(list = ls())

library(tidyverse)
library(feather)
library(scales)
library(cowplot)
library(survival)
library(survminer)
library(modelr)
library(broom)


options(width = 90L
       ,warn  = 1)

knitr::opts_chunk$set(tidy       = FALSE
                     ,cache      = FALSE
                     ,warning    = FALSE
                     ,message    = FALSE
                     ,fig.height =     8
                     ,fig.width  =    11
                     )

set.seed(421)

source("custom_functions.R")
```

Having introduced the concept of using survival analysis to investigate lapse
risks we now perform a much more in-depth analysis using various additional
techniques.


# Load Training/Test Data

We first load the training and test data into separate tables.

```{r load_data, echo=TRUE}
snapshot_date <- as.Date('2015-12-31')

train_tbl <- read_feather("data/protection_train.feather")
test_tbl  <- read_feather('data/protection_test.feather')

train_tbl %>% glimpse
test_tbl  %>% glimpse
```

We do a quick check to ensure that there are no updates in the data after the
snapshot date:

```{r perform_quick_data_checks, echo=TRUE}
train_tbl %>%
    filter(policy_statuschangedate >= snapshot_date ||
           policy_startdate        >= snapshot_date
           ) %>%
    glimpse

test_tbl %>%
    filter(policy_statuschangedate >= snapshot_date ||
           policy_startdate        >= snapshot_date
           ) %>%
    glimpse
```

Our training set is relatively large, with almost 500,000 policies to analyse
in the training set alone.

To facilitate faster computation of whatever models we choose to fit, we
randomly sample data

```{r randomly_sample_data, echo=TRUE}
use_train_tbl <- train_tbl %>%
    sample_n(50000)
```


# Basic Cox-PH Model

We return to investigating lapses using a basic Cox-PH model, so we start back
with that model.

As a reference model, we use the model with gender, smoker and the cluster as
a baseline model.

```{r fit_reference_model_coxph, echo=TRUE}
reference_model_coxph <- coxph(
    Surv(month_reached, lapsed) ~ gender_life1 + smoker_life1 + cluster_id
   ,data = use_train_tbl
)

reference_model_coxph %>% summary()
reference_model_coxph %>% tidy()
reference_model_coxph %>% glance()
```

While we have established that this model is not perfect due to the the
covariates not having a time-independent effect on the lapse rate, it is still
useful as a benchmark model for comparison purposes.

It is also simple, having just three covariates.

## Adding Covariates

We add a number of extra covariates to the model to see what effect it has.

```{r fit_basic_01_model, echo=TRUE}
basic_01_coxph <- coxph(
    Surv(month_reached, lapsed) ~ gender_life1 + smoker_life1 + cluster_id +
        mortgage_status + log(prem_ape) + age_at_policy_start + isjointlife
   ,data = use_train_tbl
)

basic_01_coxph %>% summary()
basic_01_coxph %>% tidy()   %>% print(digits = 2)
basic_01_coxph %>% glance()
```

The concordance index of this new model is slightly better at 0.575.

We do not have high expectations, but we will check the `cox.zph()` tests for
the new model. We expect it will show that the proportional hazards assumption
does not hold.

```{r plot_basic_01_zph_tests, echo=TRUE, fig.height=14, fig.width=18}
basic_01_coxph %>% cox.zph() %>% ggcoxzph(resid = FALSE)
```



## Investigate Strata

An additional way to account for time-varying effects of covariates is to
stratify the baseline hazard rate: that is, we allow different levels of
variables to have their own baseline that is modified by the proportional
hazards variables.

```{r fit_strat_gender_model, echo=TRUE}
strat_01_coxph <- coxph(
    Surv(month_reached, lapsed) ~ strata(gender_life1) + smoker_life1 +
        cluster_id + mortgage_status + log(prem_ape) + age_at_policy_start +
        isjointlife
   ,data = use_train_tbl
)

strat_01_coxph %>% summary()
strat_01_coxph %>% tidy()   %>% print(digits = 2)
strat_01_coxph %>% glance()
```

The concordance index for this is roughly the same, so we do the same for
smoking status to see if we get any improvement.


```{r fit_strat_02_model, echo=TRUE}
strat_02_coxph <- coxph(
    Surv(month_reached, lapsed) ~ strata(smoker_life1) + gender_life1 + 
        cluster_id + mortgage_status + log(prem_ape) + age_at_policy_start +
        isjointlife
   ,data = use_train_tbl
)

strat_02_coxph %>% summary()
strat_02_coxph %>% tidy()   %>% print(digits = 2)
strat_02_coxph %>% glance()
```

We quickly compare the models:

```{r compare_three_models, echo=TRUE}
list(basic_01_coxph = basic_01_coxph %>% glance
    ,strat_01_coxph = strat_01_coxph %>% glance
    ,strat_02_coxph = strat_02_coxph %>% glance) %>%
    bind_rows(.id = 'model') %>%
    select(model, n, nevent, concordance, std.error.concordance, logLik, AIC, BIC)
```

We appear to gain very little from stratifying the risks for gender and smoking
status, but we may look at this later once we use out-of-sample test data.


# Using the Survival Model

The noisy nature of the outputs of survival model and the use of the
concordance index mean it is difficult to measure the effectiveness of the
models.

Considering this, we move on to possible uses of such a model in practice,
potentially allowing us to construct some measure of model efficacy from how it
is used.

## Estimating Individual Survival Curves

We start with the simple use case of constructing individual survival curves
for each policy. The Cox model outputs a proportional hazard for each policy
and this is applied to the baseline hazard used. Having fit a Cox model, we
use this to produce each curve.

The default baseline in R takes averages of all the variables in the dataset,
including categorical variables. As these are encoded via integers we get the
silly inclusion of floating-point numbers for the values on the baseline.

Instead, we construct our own baseline entry and we use that.

```{r construct_baseline, echo=TRUE}
lapse_baseline_tbl <- data_frame(
    gender_life1        = 'F'
   ,smoker_life1        = 'N'
   ,cluster_id          = 'n6_c0'
   ,mortgage_status     = 'TERM'
   ,isjointlife         = FALSE
   ,prem_ape            = use_train_tbl %>% pull(prem_ape) %>% mean
   ,age_at_policy_start = use_train_tbl %>% pull(age_at_policy_start) %>% mean
)
```


Using this data, we calculate the baseline hazard rate predicted from our Cox
model.

```{r calculate_baseline_survival_curve, echo=TRUE}

```














