---
title: "Life Policy Book Analysis: Initial Lapse Investigation"
author: "Mick Cooney <mickcooney@gmail.com>"
date: "2018-01-04"
output:
  html_document:
    toc: true
    number_sections: true
    fig_caption: yes
    theme: cerulean
  pdf_document: default
---


```{r knit_opts, include = FALSE}
rm(list = ls())

library(tidyverse)
library(feather)
library(scales)
library(cowplot)
library(survival)
library(survminer)
library(modelr)
library(broom)


options(width = 90L
       ,warn  = 1)

knitr::opts_chunk$set(tidy       = FALSE
                     ,cache      = FALSE
                     ,warning    = FALSE
                     ,message    = FALSE
                     ,fig.height =     8
                     ,fig.width  =    11
                     )

set.seed(421)

source("custom_functions.R")
```

# Load Input Data

This worksheet loads up the data of the book of life insurance
policies and some very basic data exploration.

```{r setup_params, echo=TRUE}
data_snapshot_date <- as.Date('2015-12-31')
```

With the original dataset we had all four product types: Protection, Savings,
Pensions and Alternative Retirement Funds (ARFs).

In this analysis, we narrow the focus of our investigation into protection
policies with monthly premium with sum assureds of less than one million euro
as larger risks are generally subjected to more rigourous underwriting and
tend to have different customer behaviour.

```{r load_data, echo=TRUE}
lifebook_tbl <- read_feather("data/lifebook_cleaned.feather")
                        
protection_book_tbl <- lifebook_tbl %>%
    filter(prod_type   == 'protection'
          ,prem_freq   == 12
          ,prem_type   == 'RP'
          ,sum_assured <= 1e6
           )

protection_book_tbl %>% glimpse
```

So we have 670,000 protection policies in our set for analysis.

This dataset will be the basis of our lapse investigation, but to do so we
need to create a few extra derived variables.

## Create Derived Values

Now that we have loaded the data we do a bit of feature engineering to
calculate a few new and useful variables.

```{r do_feature_engineering, echo=TRUE, results='hide'}
protection_book_tbl <- protection_book_tbl %>%
    mutate(age_at_data_snapshot = as.numeric((data_snapshot_date - dob_life1) / 365.25)
          ,age_at_policy_start  = as.numeric((policy_startdate   - dob_life1) / 365.25)
          ,month_reached        = case_when(
              policy_status == 'lapsed'    ~ as.numeric(policy_statuschangedate - policy_startdate) / 30.4
             ,policy_status == 'completed' ~ as.numeric(policy_duration * 12)
             ,policy_status == 'inforce'   ~ as.numeric(data_snapshot_date - policy_startdate) / 30.4
                ) %>% round(0) %>% as.integer
    ) %>%
    filter(month_reached > 0)

protection_book_tbl %>% glimpse
```

We now need to do some basic exploration of the variables before we model them.


## Exploration of Derived Values

First we make some simple univariate plots of the derived values.

```{r data_exploration_vars, echo=TRUE}
dataexp_level_exclusion_threshold <- 100

dataexp_cat_level_count <- 40
dataexp_hist_bins_count <- 50
```



```{r create_univariate_numeric_plots, echo=TRUE, warning=FALSE}
derived_vars <- c('age_at_data_snapshot', 'age_at_policy_start', 'month_reached')

for(plot_varname in derived_vars) {
    cat("--\n")
    cat(paste0(plot_varname, '\n'))

    plot_var <- protection_book_tbl %>% .[[plot_varname]]
    na_count <- plot_var %>% is.na %>% sum

    plot_var %>% summary %>% print

    explore_plot <- ggplot(protection_book_tbl) +
        geom_histogram(aes_string(x = plot_varname), bins = dataexp_hist_bins_count) +
        geom_vline(xintercept = mean  (plot_var, na.rm = TRUE), colour = 'red',   size = 1.5) +
        geom_vline(xintercept = median(plot_var, na.rm = TRUE), colour = 'green', size = 1.5) +
        xlab(plot_varname) +
        ylab("Count") +
        scale_x_continuous(labels = comma) +
        scale_y_continuous(labels = comma) +
        ggtitle(paste0('Histogram Plot for Variable: ', plot_varname
                      ,' (', na_count, ' missing values)')
               ,subtitle = '(red line is mean, green line is median)')

    print(explore_plot)
}
```


## Set Categorical Reference Levels

We want to set a reference level for each of the categorical variables in the
dataset to aid with interpretation so we convert a number of the character
variables to be factors with a given reference.

```{r set_categorical_references, echo=TRUE}
protection_book_tbl <- protection_book_tbl %>%
    mutate(
        mortgage_status = mortgage_status %>% as_factor %>% relevel(ref = 'TERM')
       ,cluster_id      = cluster_id      %>% as_factor %>% relevel(ref = 'n6_c0')   
       ,gender_life1    = gender_life1    %>% as_factor %>% relevel(ref = 'M')
       ,smoker_life1    = smoker_life1    %>% as_factor %>% relevel(ref = 'N')
        )

```




# Initial Empirical Lapse Analysis

Prior to starting our model we want to look at the progression of monthly lapse
rates.

To calculate this data we need to count the number of in-force policies during
each month as well as the count of policies that lapsed in that month.

We do this by calculating the cumulative sum of policy starts in each month, as
well as the counts of policies going out-of-force from lapses or reaching
end-of-life. The difference of the two gives us a count of in-force policies on
the book each month, and we then use this to calculate the empirical lapse rate.

Note that we round all dates to the start of the month and so there are slight
timing issues around that, but we can ignore those for now.

```{r calculate_monthly_lapses, echo=TRUE}
tstamp_first_month <- protection_book_tbl %>%
    pull(policy_startdate) %>%
    min() %>%
    format('%Y-%m-01') %>%
    as.Date()

tstamp_months_tbl <- data_frame(tstamp_month = seq(tstamp_first_month, data_snapshot_date, by = 'month'))


count_start_tbl <- protection_book_tbl %>%
    mutate(start_month  = policy_startdate %>% format("%Y-%m-01") %>% as.Date()) %>%
    count(start_month) %>%
    rename(start_count = n)

count_end_tbl <- protection_book_tbl %>%
    mutate(oof_date = case_when(
                policy_status == 'lapsed' ~ policy_statuschangedate
               ,TRUE                      ~ policy_enddate
                )
          ,oof_month = oof_date %>% format('%Y-%m-01') %>% as.Date()
    ) %>%
    count(oof_month) %>%
    rename(oof_count = n)


count_lapse_tbl <- protection_book_tbl %>%
    filter(policy_status == 'lapsed') %>%
    mutate(lapse_month = policy_statuschangedate %>% format('%Y-%m-01') %>% as.Date()) %>%
    count(lapse_month) %>%
    rename(lapse_count = n)


lapse_data_tbl <- tstamp_months_tbl %>%
    left_join(count_start_tbl, by = c('tstamp_month' = 'start_month')) %>%
    left_join(count_end_tbl,   by = c('tstamp_month' = 'oof_month')) %>%
    left_join(count_lapse_tbl, by = c('tstamp_month' = 'lapse_month')) %>%
    replace_na(list(start_count = 0, oof_count = 0, lapse_count = 0)) %>%
    mutate(inforce_count = cumsum(start_count) - cumsum(oof_count)
          ,lapse_rate    = lapse_count / inforce_count
          )
```

With the lapse data calculate we now want to look at the lapse rate.

```{r plot_empirical_lapse_rate, echo=TRUE}
ggplot(lapse_data_tbl) +
    geom_line(aes(x = tstamp_month, y = lapse_rate)) +
    expand_limits(y = 0) +
    xlab('Month') +
    ylab('Lapse Rate') +
    ggtitle('Lineplot of the Monthly Empirical Lapse Rate')
```

The early lapse rate is very noisy, probably due to the effects of the business
starting up and so low policy counts. To check this, we need to look at time
based effects of policy starts and the count of policies in force.

```{r plot_policy_inforce_count, echo=TRUE}
ggplot(lapse_data_tbl) +
    geom_line(aes(x = tstamp_month, y = inforce_count)) +
    expand_limits(y = 0) +
    scale_y_continuous(labels = comma) +
     xlab('Month') +
    ylab('Count of In-force Policies') +
    ggtitle('Lineplot of the Monthly In-force Policy Count')
```

We see a steady increase in the inforce book, with it peaking around 2008 or
so, declining after that. This may be due to a number of reasons, so we look
at the patterns for new policies as well.

```{r plot_policy_start_count, echo=TRUE}
ggplot(lapse_data_tbl) +
    geom_line(aes(x = tstamp_month, y = start_count)) +
    expand_limits(y = 0) +
    scale_y_continuous(labels = comma) +
    xlab('Month') +
    ylab('Count of New Policies') +
    ggtitle('Lineplot of the Monthly New Policy Count')
```

This plot suggests a strong calendar pattern for new policies, but is otherwise
fairly constant with a noticeable upshift in levels froms the years 2000-2010.

This makes sense for Ireland as this coincides with a huge property boom during
that period, which fuelled a huge demand for life insurance tied to mortgages.

Beyond that, the pattern observed for the in-force book is due to the mismatch
between the observed window of time and the duration of policies. Many polices
have a duration of over twenty years, so the inforce levels of policies need
more time to stabilise.

As a final comparison, we will plot both the lapse rate and the count of
in-force policies together on a single panel plot. We plot from the start of 1996
to reduce the effects of the initial years from the plot


```{r plot_lapse_inforce, echo=TRUE}
plot_tbl <- lapse_data_tbl %>%
    filter(tstamp_month >= as.Date('1996-01-01')) %>%
    dplyr::select(tstamp_month, lapse_rate, inforce_count) %>%
    gather('key', 'value', -tstamp_month)

ggplot(plot_tbl) + 
    geom_line(aes(x = tstamp_month, y = value)) +
    expand_limits(y = 0) +
    facet_wrap(~key, ncol = 1, scales = 'free_y') +
    scale_y_continuous(labels = comma) +
    xlab('Month') +
    ylab('Value')
```

## Investigating the Recession

We would like to identify the jump in lapse rates and determine the start and
end dates for this. 2006 was still the boom times and it was over by the end of
2013, so we plot those times first.

```{r plot_boom_lapses, echo=TRUE}
ggplot(lapse_data_tbl %>% filter(tstamp_month >= as.Date('2007-01-01')
                                ,tstamp_month <= as.Date('2013-12-31'))) +
    geom_line(aes(x = tstamp_month, y = lapse_rate)) +
    expand_limits(y = 0) +
    xlab('Month') +
    ylab('Lapse Rate') +
    ggtitle('Lineplot of the Monthly Empirical Lapse Rate for Boom Times')
```

Looking at this data, it seems reasonable to flag the recession as starting at
the beginning of 2008 and ending at the end of 2012.

```{r add_lapse_flags, echo=TRUE}
lapse_data_tbl <- lapse_data_tbl %>%
    mutate(epoch_label = case_when(
               tstamp_month <  as.Date('2008-01-01')       ~ 'Pre-Recession'
              ,tstamp_month >= as.Date('2008-01-01') &
               tstamp_month <= as.Date('2012-12-31')       ~ 'Recession'
              ,TRUE                                        ~ 'Post-Recession'
            )
        )


ggplot(lapse_data_tbl %>% filter(tstamp_month >= as.Date('2007-01-01')
                                ,tstamp_month <= as.Date('2013-12-31'))) +
    geom_line(aes(x = tstamp_month, y = lapse_rate, colour = epoch_label)) +
    expand_limits(y = 0) +
    xlab('Month') +
    ylab('Lapse Rate') +
    ggtitle('Lineplot of the Monthly Empirical Lapse Rate around Recession')
```

These epochs will be useful later when accounting for the recession in future
models.


## Data Censorship

One final investigation that may be useful is to see how much censorship we
have in our data. We observed the status of the book of policies at a given
point in time - the end of 2015, and so we do not have complete observation of
the life times of the policies. Many of the policy lifetimes are
*left-censored* as a result.

In the case where the amount of censoring is small relative to the size of the
dataset we could potentially ignore it, otherwise our modelling will need to
account for this phenomenon in the data.

To check the prevalence of censoring, we do a simple check of the proportions
of the different policy statuses in our data.


```{r calculate_status_proportions, echo=TRUE}
ggplot(lifebook_tbl %>% count(policy_status)) +
    geom_col(aes(x = policy_status, y = n)) +
    scale_y_continuous(labels = comma) +
    xlab('Policy Status') +
    ylab('Count') +
    ggtitle('Plot of Proportions of Policy Status (All Data)')
```

Looking at all the data, it appears there is significant censoring. That said,
we may decide that older lapse patterns are different from today, and so we
restrict this plot to more recent policies (say from 2000 on and from 2005 on)

```{r plot_status_props_filtered, echo=TRUE}
ggplot(lifebook_tbl %>% filter(policy_startdate >= as.Date('2000-01-01')) %>% count(policy_status)) +
    geom_col(aes(x = policy_status, y = n)) +
    scale_y_continuous(labels = comma) +
    xlab('Policy Status') +
    ylab('Count') +
    ggtitle('Plot of Proportions of Policy Status (post 2000)')


ggplot(lifebook_tbl %>% filter(policy_startdate >= as.Date('2005-01-01')) %>% count(policy_status)) +
    geom_col(aes(x = policy_status, y = n)) +
    scale_y_continuous(labels = comma) +
    xlab('Policy Status') +
    ylab('Count') +
    ggtitle('Plot of Proportions of Policy Status (post 2000)')
```

Focusing on more recent policies we see that censoring becomes more and more
important, so we need to account for this in our modelling.

For this reason, we will look at various survival analysis techniques as these
naturally allow for the censorship of the data.


Before we move on to more formal modelling, it is interesting to see the
difference between censored and non-censored observations in the data.

To do that, we create two histograms and look at the different distributions.


```{r plot_cens_noncens_lifetimes, echo=TRUE}
ggplot(protection_book_tbl) +
    geom_histogram(aes(x = month_reached), bins = 50) +
    facet_wrap(~ lapsed, ncol = 2) +
    scale_y_continuous(labels = comma) +
    xlab("Observed Lifetime") +
    ylab("Count") +
    ggtitle("Lifetime Comparison for Lapsed and Non-lapsed Policies")
```

Once more we filter out the older policies in the book, and look at post-2000
and post-2005 policies:

```{r plot_cens_noncens_lifetimes_2000, echo=TRUE}
ggplot(protection_book_tbl %>% filter(policy_startdate >= as.Date('2000-01-01'))) +
    geom_histogram(aes(x = month_reached), bins = 50) +
    facet_wrap(~ lapsed, ncol = 2) +
    scale_y_continuous(labels = comma) +
    xlab("Observed Lifetime") +
    ylab("Count") +
    ggtitle("Lifetime Comparison for Lapsed and Non-lapsed post-2000 Policies")
```



```{r plot_cens_noncens_lifetimes_2005, echo=TRUE}
ggplot(protection_book_tbl %>% filter(policy_startdate >= as.Date('2005-01-01'))) +
    geom_histogram(aes(x = month_reached), bins = 50) +
    facet_wrap(~ lapsed, ncol = 2) +
    scale_y_continuous(labels = comma) +
    xlab("Observed Lifetime") +
    ylab("Count") +
    ggtitle("Lifetime Comparison for Lapsed and Non-lapsed post-2005 Policies")
```



# Using Survival Analysis Techniques

Having done our preliminary analysis, we now turn our attention to the use of
survival analysis techniques to tackle this problem as a large proportion of
our data is censored.

## Kaplan-Meier Estimates

One of the first things we can look at is the Kaplan-Meier estimates for this
data, first looking at the all the data without splitting along any categorical
variables.

```{r create_simple_km_estimate, echo=TRUE}
lapse_basic_km <- survfit(Surv(month_reached, lapsed) ~ 1
                         ,data = protection_book_tbl)

ggsurvplot(lapse_basic_km, censor = FALSE, break.time.by = 12, conf.int = TRUE)
```

This looks like a roughly exponential curve, though with a slightly higher
cumulative survival for the 24-60 month period. We will return to this
comparison later.

Now we look at alternative KM estimates, splitting the data on both gender
and the smoking status of the primary policy holder.

```{r create_gender_km_estimate, echo=TRUE}
lapse_gender_km <- survfit(Surv(month_reached, lapsed) ~ gender_life1
                          ,data = protection_book_tbl)

ggsurvplot(lapse_gender_km, censor = FALSE, break.time.by = 12, conf.int = TRUE)
```

We can see distinct differences between male and female policy holders in
terms of expected time to lapse, especially for in the periods between 12-60
months. This is likely affected by differences in premium charged as before the
2012 Gender Price Directive, gender was a big price differentiator for life
insurance policies and we surmise that a higher premium raises the likelihood
of a policy lapsing.

It is interesting to note that any differences in gender are largely gone after
about ten years of policy lifetime.

We now move on to investigating lapse differences for smokers.

```{r create_smoker_km_estimate, echo=TRUE}
lapse_smoker_km <- survfit(Surv(month_reached, lapsed) ~ smoker_life1
                          ,data = protection_book_tbl)

ggsurvplot(lapse_smoker_km, censor = FALSE, break.time.by = 12, conf.int = TRUE)
```

There are three smoking statuses: Smoker, Non-Smoker and Quitter, so we get
three KM estimates. Here the message is more nuanced - smokers lapse more
often early on, but become the least likely to lapse after 72 months or so.


# Cox Proportional Hazards Model

We now want to look at building regression models for our data, so we first
split our data into the traditional machine-learning train/test split.

```{r split_data, echo=TRUE}
test_prop <- 0.4

split_lst <- protection_book_tbl %>%
    resample_partition(c(train = 1 - test_prop, test = test_prop))
```

We output the split for later use in further worksheets.

```{r output_train_test_data_split, echo=TRUE}
split_lst$train %>% as_data_frame %>% write_feather(path = 'data/protection_train.feather')
split_lst$test  %>% as_data_frame %>% write_feather(path = 'data/protection_test.feather')
```



## Initial Exploratory Models

To get a feel for the types of models we want to build and how they might
work, we focus initially on the `gender` and `smoker` variables to start.

Note that we are still very much in the 'exploration' phase: the purposes of
these models is to get a feel for the data - we are not yet moving on to
producing models for the purposes of prediction just yet.

For our first model, we simply fit the data to the gender parameter:

```{r fit_01_model, echo=TRUE}
basic_01_coxph <- coxph(Surv(month_reached, lapsed) ~ gender_life1
                       ,data = split_lst$train
                        )

basic_01_coxph %>% summary()
basic_01_coxph %>% tidy()
basic_01_coxph %>% glance()
```

The concordance index for this model is about 0.51 - only slightly above the
reference level of 0.50, so this model contains little in the way of predictive
power.

We also want to add smoking status, so we try that. We will look at its effect
as the sole predictor first.

```{r fit_02_model, echo=TRUE}
basic_02_coxph <- coxph(Surv(month_reached, lapsed) ~ smoker_life1
                       ,data = split_lst$train
                        )

basic_02_coxph %>% summary()
basic_02_coxph %>% tidy()
basic_02_coxph %>% glance()
```

Once again we have a low concordance index for this model, so we need to do
better.

We do have a socio-economic clustering in this data, and we do know that this
had a profound effect on the economy with young families losing their job and
forgoing their mortgage for example, so we look at that.

```{r fit_03_model, echo=TRUE}
basic_03_coxph <- coxph(
    Surv(month_reached, lapsed) ~ cluster_id
   ,data = split_lst$train
                        )

basic_03_coxph %>% summary()
basic_03_coxph %>% tidy()
basic_03_coxph %>% glance()
```

The concordance index is now over 0.56 so the cluster of the policy owner
contains predictive power for the propensity of the policy to lapse.

We now look at the model with all three predictors combined as predictors in
the model.

```{r fit_04_model, echo=TRUE}
basic_04_coxph <- coxph(
    Surv(month_reached, lapsed) ~ gender_life1 + smoker_life1 + cluster_id
   ,data = split_lst$train
)
```

Note that the model with just the `cluster_id` as a predictor gives a better
concordance than models with more variables, which is counterintuitive from
a regression point of view. This definitely requires investigation, as it is
likely due to violations of the assumptions of the Cox-PH model. Even so, we
would hope for a better concordance index than 0.56, so we need a more thorough
analysis.


## Testing the Model Assumptions

Another possible reason for the lack of predictive power in the model is because
the assumptions in the model may not hold.

The main assumption of the CoxPH models is for the coefficients of the model
to be constant over time. We first check the univariate model with gender:

```{r test_ph_assumptions_model_01, echo=TRUE, fig.height=10, fig.width=14}
basic_01_coxph %>% cox.zph() %>% ggcoxzph(resid = FALSE)
```

It is pretty clear that gender has an effect, but is not a time-independent
effect. This is something we will need to deal with somehow.

```{r test_ph_assumptions_model_02, echo=TRUE, fig.height=10, fig.width=14}
basic_02_coxph %>% cox.zph() %>% ggcoxzph(resid = FALSE)
```

Smoking status seems very similar to gender - there is an effect, but it not
time-independent.

We look at the clustering now.

```{r test_ph_assumptions_model_03, echo=TRUE, fig.height=10, fig.width=14}
basic_03_coxph %>% cox.zph() %>% ggcoxzph(resid = FALSE)
```

The clustering is around 0 for some of the levels, but the signification ones
are not time-independent.

Finally, we look at the combined model, which we expect to give us a similar
message.


```{r test_ph_assumptions_model_04, echo=TRUE, fig.height=10, fig.width=14}
basic_04_coxph %>% cox.zph() %>% ggcoxzph(resid = FALSE)
```


## Using the Secret Weapon

We now use a simple technique known as the 'Secret Weapon' by Andrew Gelman.
With this method we partition the data along various dimensions, fitting the
same model to each partition and then plotting coefficients together to get a
sense of the variability.

We know that the CoxPH model has issues as it violates the assumptions of the
model, but it is likely to be instructive anyway. We will almost make a plot
of the concordance index as well as the p-value from the `cox.zph()` test to
see if there are any calendar patterns to the violation of the assumptions.


```{r split_data_by_policy_year, echo=TRUE}
secretweapon_year_lst <- split_lst$train %>%
    as_data_frame() %>%
    mutate(split_label = format(policy_startdate, '%Y')) %>%
    split(.$split_label) %>%
    map(~ coxph(Surv(month_reached, lapsed) ~ gender_life1 + smoker_life1 + cluster_id
               ,data = .))

coefs_tbl <- secretweapon_year_lst %>%
    map(tidy) %>%
    bind_rows(.id = 'start_year')

metrics_tbl <- secretweapon_year_lst %>%
    map(glance) %>%
    bind_rows(.id = 'start_year') %>%
    transmute(start_year
             ,term      = 'concordance'
             ,estimate  = concordance
             ,std.error = std.error.concordance)

secretweapon_year_tbl <- list(coefs_tbl, metrics_tbl) %>%
    bind_rows() %>%
    mutate(start_year = start_year %>% as.integer)
```

Having calculated both the parameter coefficients and the concordance index after
splitting the data by policy year, we now plot the coefficients of the model
as well as the concordance index, including the error bars.


```{r plot_secret_weapon_values, echo=TRUE}
ggplot(secretweapon_year_tbl) +
    geom_point(aes(x = start_year, y = estimate)) +
    geom_errorbar(aes(x    = start_year
                     ,ymin = estimate - 2 * std.error
                     ,ymax = estimate + 2 * std.error)
                 ,width = 0) +
    expand_limits(y = 0) +
    facet_wrap(~term, scales='free_y') +
    xlab("Start Year") +
    ylab("Parameter Value") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```

Finally, we do a plot of the p-values from the `cox.zph()` test and construct
the same plot.


```{r show_split_test_metrics, echo=TRUE}
extract_test_values <- function(input) {
    test_tbl <- input %>%
        cox.zph() %>%
        .$table %>%
        as.data.frame() %>%
        rownames_to_column('term')

    return(test_tbl)
}


secretweapon_year_test_tbl <- secretweapon_year_lst %>%
    map(extract_test_values) %>%
    bind_rows(.id = 'start_year') %>%
    mutate(start_year = start_year %>% as.integer)


ggplot(secretweapon_year_test_tbl) +
    geom_point(aes(x = start_year, y = p)) +
    expand_limits(y = 0) +
    facet_wrap(~term) +
    xlab("Start Year") +
    ylab("Parameter Value") +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
```


It seems pretty clear that while there appears to be a calendar effect on the
lapse rates, it does not affect the violation of CoxPH assumptions.


























